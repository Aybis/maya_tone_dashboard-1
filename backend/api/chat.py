from flask import Blueprint, request, jsonify
import json, sqlite3
from datetime import datetime, timedelta
from ..prompts import BASE_SYSTEM_PROMPT
from ..config import MAX_CONTEXT_MESSAGES, JIRA_USERNAME
from ..db import insert_message, fetch_recent_messages, get_pending_action, set_pending_action, clear_pending_action, touch_chat
from ..services.openai_service import get_client, check_confirmation_intent
from ..services.tool_dispatcher import execute as execute_tool

# Blueprint providing chat session lifecycle + AI question answering with tool/function calling.
# Flow (ask endpoint):
# 1. Save user message.
# 2. If there is a pending action awaiting confirmation (stored earlier), classify reply as confirm/cancel.
# 3. If confirming: execute the stored tool and then summarise result with a second AI pass.
# 4. Else build conversation context (recent N messages + system prompt) and call OpenAI with tool definitions.
# 5. If model returns a tool call, execute it and either (a) directly build a chart fallback or (b) feed tool result back for summarisation.
# 6. Persist assistant response and return to client.
# Safety: Any tool execution errors are caught and surfaced in assistant reply.

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/api/chat/new', methods=['POST'])
def new_chat():
    """Create a new chat row with autogenerated whimsical title."""
    conn = sqlite3.connect('maya_tone.db'); c = conn.cursor()
    from uuid import uuid4; import random
    chat_id = str(uuid4())
    WORDS = ['Orion','Lumen','Echo','Nova','Aster','Nimbus','Quartz','Atlas','Zenith','Pulse','Vertex','Cipher','Delta','Photon','Vortex','Comet','Helix','Matrix']
    title = f"{random.choice(WORDS)} {random.choice(WORDS)} {datetime.now().strftime('%H:%M')}"
    c.execute('INSERT INTO chats (id, title, created_at, updated_at, user_id) VALUES (?, ?, ?, ?, ?)', (chat_id, title, datetime.now(), datetime.now(), 'user'))
    conn.commit(); conn.close(); return jsonify({'chat_id': chat_id, 'title': title})

@chat_bp.route('/api/chat/history')
def history():
    """Return list of chats (id + title) ordered by latest update."""
    conn = sqlite3.connect('maya_tone.db'); conn.row_factory = sqlite3.Row
    c = conn.cursor(); c.execute('SELECT id, title FROM chats ORDER BY updated_at DESC')
    rows = [dict(r) for r in c.fetchall()]; conn.close(); return jsonify(rows)

@chat_bp.route('/api/chat/<chat_id>')
def messages(chat_id):
    """Return chronological messages for a chat."""
    conn = sqlite3.connect('maya_tone.db'); conn.row_factory = sqlite3.Row
    c = conn.cursor(); c.execute('SELECT content, sender FROM messages WHERE chat_id = ? ORDER BY timestamp ASC', (chat_id,))
    msgs = [dict(r) for r in c.fetchall()]; conn.close(); return jsonify(msgs)

@chat_bp.route('/api/chat/<chat_id>/delete', methods=['DELETE'])
def delete_chat(chat_id):
    """Delete chat and all messages."""
    conn = sqlite3.connect('maya_tone.db'); c = conn.cursor()
    c.execute('DELETE FROM messages WHERE chat_id = ?', (chat_id,)); c.execute('DELETE FROM chats WHERE id = ?', (chat_id,))
    conn.commit(); conn.close(); return jsonify({'success': True})

@chat_bp.route('/api/chat/<chat_id>/title', methods=['PUT'])
def rename_chat(chat_id):
    """Rename chat (title)."""
    data = request.json or {}; title = (data.get('title','') or '').strip()
    if not title: return jsonify({'success': False, 'error':'Empty title'}), 400
    conn = sqlite3.connect('maya_tone.db'); c = conn.cursor()
    c.execute('UPDATE chats SET title = ?, updated_at = ? WHERE id = ?', (title, datetime.now(), chat_id))
    conn.commit(); conn.close(); return jsonify({'success': True})

@chat_bp.route('/api/chat/<chat_id>/ask', methods=['POST'])
def ask(chat_id):
    """Primary conversational endpoint.

    Accepts: {"message": "..."}
    Returns: { success: bool, answer: str }

    Behaviour details:
    - Maintains conversation context (last MAX_CONTEXT_MESSAGES user/assistant messages).
    - Provides OpenAI function-calling tools for Jira aggregation & issue search.
    - Handles confirmation workflow (stored pending action) via lightweight intent classifier.
    - Emits chart spec blocks with ```chart fences when aggregation requested or fallback triggered.
    """
    payload = request.json or {}; user_message = (payload.get('message') or '').strip()
    if not user_message:
        return jsonify({'success': False, 'answer': 'Pesan tidak boleh kosong.'})
    client = get_client();
    if not client: return jsonify({'success': False, 'answer':'OpenAI tidak tersedia.'})
    insert_message(chat_id, user_message, 'user')

    def send(answer):
        """Persist assistant message & update chat timestamp before responding."""
        insert_message(chat_id, answer, 'assistant'); touch_chat(chat_id)
        return jsonify({'success': True, 'answer': answer})

    # 1. Confirmation flow check
    pending = get_pending_action(chat_id)
    if pending:
        intent = check_confirmation_intent(user_message, client).get('intent')
        clear_pending_action(chat_id)
        if intent == 'cancel': return send('❌ Baik, aksi dibatalkan.')
        if intent == 'confirm':
            action = json.loads(pending)
            name = action['name']; args = action['args']
            data_res, err = execute_tool(name, args)
            if err: return send(f"❌ Error eksekusi: {err}")
            # Second pass summarisation with tool result appended
            history_msgs = fetch_recent_messages(chat_id, MAX_CONTEXT_MESSAGES)
            messages_ = [{'role':'system','content': BASE_SYSTEM_PROMPT}] + history_msgs + [{'role':'assistant','content': f"✅ Aksi '{name}' sukses: {json.dumps(data_res, ensure_ascii=False)}"}]
            second = client.chat.completions.create(model='gpt-4o-mini', messages=messages_, temperature=0.1)
            return send(second.choices[0].message.content)

    # 2. Normal flow: build context
    history_msgs = fetch_recent_messages(chat_id, MAX_CONTEXT_MESSAGES)
    messages_ = [{'role':'system','content': BASE_SYSTEM_PROMPT}] + history_msgs
    now = datetime.now(); current_date = now.strftime('%Y-%m-%d')
    month_start = now.replace(day=1).strftime('%Y-%m-%d')
    last_month_start = (now.replace(day=1) - timedelta(days=1)).replace(day=1).strftime('%Y-%m-%d')
    last_month_end = (now.replace(day=1) - timedelta(days=1)).strftime('%Y-%m-%d')
    tools = [
        {"type":"function","function":{"name":"aggregate_issues","description":"Agregasi issue untuk chart","parameters":{"type":"object","properties":{"group_by":{"type":"string","enum":["status","priority","assignee","type","created_date"]},"from_date":{"type":"string"},"to_date":{"type":"string"},"jql_extra":{"type":"string"}},"required":["group_by"]}}},
        {"type":"function","function":{"name":"get_issues","description":f"Cari issue via JQL gunakan tanggal real-time: today={current_date} month_start={month_start}","parameters":{"type":"object","properties":{"jql_query":{"type":"string"}},"required":["jql_query"]}}},
    ]
    response = client.chat.completions.create(model='gpt-4o-mini', messages=messages_, tools=tools, tool_choice='auto', temperature=0.1)
    rmsg = response.choices[0].message

    # 3. No tool call case (may still ask for a chart => fallback quick aggregation)
    if not getattr(rmsg,'tool_calls', None):
        if any(k in user_message.lower() for k in ['chart','grafik','diagram','visual','pie','bar','line']):
            data_res, err = execute_tool('aggregate_issues', {'group_by':'status'})
            counts = (data_res or {}).get('counts', []) if not err else []
            labels = [c['label'] for c in counts][:10]; values = [c['value'] for c in counts][:10]
            chart = {'title':'Distribusi Issue (Fallback)','type':'bar','labels':labels,'datasets':[{'label':'Jumlah','data':values,'backgroundColor':['#3b82f6']*len(values)}],'meta':{'group_by':'status','filters':{}},'notes':'Fallback'}
            return send(f"```chart\n{json.dumps(chart, ensure_ascii=False)}\n```")
        return send(rmsg.content or 'Tidak ada jawaban.')

    # 4. Handle tool call result
    call = rmsg.tool_calls[0]; fname = call.function.name; args = json.loads(call.function.arguments)
    data_res, err = execute_tool(fname, args)
    if err: return send(f"❌ Error: {err}")

    # 4a. Short-circuit for aggregation to emit chart spec directly
    if fname == 'aggregate_issues':
        labels = [c['label'] for c in data_res['counts']][:40]; values = [c['value'] for c in data_res['counts']][:40]
        chart = {'title': f'Agg by {data_res['group_by']}','type':'bar','labels':labels,'datasets':[{'label':'Jumlah','data':values,'backgroundColor':['#3b82f6','#06b6d4','#8b5cf6','#f59e0b','#ef4444']*(len(values)//5+1)}],'meta':{'group_by':data_res['group_by']},'notes':'Gunakan filter'}
        return send(f"```chart\n{json.dumps(chart, ensure_ascii=False)}\n```\nTotal {data_res['total']} issue.")

    # 4b. Two-step summarisation for non-chart tools
    tool_call_id = call.id
    summarizer_messages = messages_ + [
        {"role":"assistant","content":None,"tool_calls":[{"id":tool_call_id,"type":"function","function":{"name":fname,"arguments":call.function.arguments}}]},
        {"tool_call_id": tool_call_id, "role": "tool", "name": fname, "content": json.dumps(data_res, ensure_ascii=False)}
    ]
    second = client.chat.completions.create(model='gpt-4o-mini', messages=summarizer_messages, temperature=0.1)
    return send(second.choices[0].message.content)
